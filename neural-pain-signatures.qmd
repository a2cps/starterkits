# Prior Neural Pain Signature Responses {#sec-neural-pain-signatures}

## Before Proposing Project

### Confirm Sample Size

Not all participants in a release have imaging, and depending on the application not all MRIs may be of sufficient quality. Before proposing a project, please confirm that a release will have a large enough sample size. Release 2.0 has 716 participants with the primary task fMRI biomarker: NPS [@wager_fmri-based_2013] and SIIPS-1 [@woo_quantifying_2017]. 

## Starting Project

### Locate data

{{< include _snippets/mri-location.qmd >}}

The signature response are underneath `derivatives/signatures`

```bash
$ ls derivatives/signatures/
cleaned    confounds.json      signatures-by-part-diff       signatures-by-part.json  signatures-by-run-diff       signatures-by-run.json  signatures-by-tr-diff       signatures-by-tr.json
confounds  signatures-by-part  signatures-by-part-diff.json  signatures-by-run        signatures-by-run-diff.json  signatures-by-tr        signatures-by-tr-diff.json
```

Signature responses are stored either "by-run" (that is, one response per scan), "by-part" (three responses per run corresponding to the three parts for which participants provided pain ratings), or "by-tr" (one response for every volume). The biomarker corresponds to the values that are "by-run". Additionally, responses may be calculated with only the data from a single run (e.g., a "by-run" response for REST1, CUFF1, CUFF2, and REST2), or they may be calculated as a difference ("diff") between one of the CUFF scans and one of the REST scans. 

Each signature response folder contains a table of values, and `*.json` sidecars are [data dictionaries that conform to BIDS ](https://bids-specification.readthedocs.io/en/v1.9.0/common-principles.html#tabular-files). The data dictionary for responses "by-run" is copied below.

```json
{
    "signature": {
        "LongName": "Signature",
        "Description": "Index for of Signature. See signature_labels.json"
    },
    "correlation": {
        "LongName": "Correlation",
        "Description": "Signature as Estimated by Correlation"
    },
    "dot": {
        "LongName": "Dot Product",
        "Description": "Signature as Estimated by Dot Product"
    },
    "cosine": {
        "LongName": "Cosine Similarity",
        "Description": "Signature as Estimated by Cosine Similarity"
    },
    "sub": {
        "LongName": "Subject",
        "Description": "Study Participant, BIDS Subject ID",
        "TermURL": "https://bids-specification.readthedocs.io/en/v1.9.0/appendices/entities.html#sub"
    },
    "ses": {
        "LongName": "Session",
        "Description": "Visit, Protocol, BIDS Session ID",
        "Levels": {
            "V1": "baseline_visit",
            "V3": "3mo_postop"
        },
        "TermURL": "https://bids-specification.readthedocs.io/en/v1.9.0/appendices/entities.html#ses"
    },
    "task": {
        "LongName": "Task",
        "Description": "Functional MRI Task, BIDS Task ID",
        "Levels": {
            "cuff": "cuff pressure scan",
            "rest": "resting state scan"
        },
        "TermURL": "https://bids-specification.readthedocs.io/en/v1.9.0/appendices/entities.html#task"
    },
    "run": {
        "LongName": "Run",
        "Description": "Task Run Number, BIDS Run ID",
        "TermURL": "https://bids-specification.readthedocs.io/en/v1.9.0/appendices/entities.html#run"
    }
}
```

Note: the table mentions "session", but in this release only V1 (baseline) results are available.

### Extract data

The tabular data comprise parquet files that have been partitioned in a [hive-style](https://hive.apache.org/). That is, subfolders names contain column information – in this case subject ID (REDCap Record ID), task, and run. 

```bash
$ tree signature-by-run
signature-by-run
├── sub=10003
│  └── ses=V1
│     ├── task=cuff
│     │  └── run=1
│     │     └── part-0.parquet
│     └── task=rest
│        ├── run=1
│        │  └── part-0.parquet
│        └── run=2
│           └── part-0.parquet
├── sub=10008
│  └── ses=V1
│     ├── task=cuff
│     │  └── run=1
│     │     └── part-0.parquet
│     └── task=rest
│        ├── run=1
│        │  └── part-0.parquet
│        └── run=2
```

The biomarker is based on the CUFF1 (task=cuff/run=1) scan. The other scans are available for secondary analyses, but please note that not all participants have all tasks and runs available.

To load the whole dataset, the parquet files may be read individually or using a tool that is aware of the hive-partitioning structure. In `R`, a good choice is the [`arrow`](https://arrow.apache.org/docs/r/index.html) library.

```{r}
#| eval: FALSE
library(arrow)
library(dplyr)
library(tidyr)

open_dataset("data/signatures-by-run") |> 
  filter(signature %in% c("grouppred_cvpcr", "137subjmap_weighted_mean")) |>
  filter(task=="cuff", run==1) |>
  select(signature, value=correlation, sub, ses) |>
  collect() |>
  pivot_wider(names_from = signature) |>
  rename(
    SIIPS1=`137subjmap_weighted_mean`,
    NPS=`grouppred_cvpcr`)
```

```bash
# A tibble: 716 × 4
     sub ses     SIIPS1      NPS
   <int> <chr>    <dbl>    <dbl>
 1 10011 V1    -0.00652 -0.0740 
 2 10010 V1    -0.0611  -0.0200 
 3 10003 V1    -0.00162  0.0331 
 4 10008 V1    -0.0407  -0.0581 
 5 10013 V1    -0.0279   0.0234 
 6 10014 V1    -0.00120 -0.0146 
 7 10015 V1    -0.0576  -0.0178 
 8 10017 V1    -0.0165   0.0263 
 9 10020 V1    -0.0103  -0.0530 
10 10023 V1     0.0116  -0.00789
# ℹ 706 more rows
# ℹ Use `print(n = ...)` to see more rows
```

In python, a good choice is the [`polars`](https://docs.pola.rs/) library

```{python}
#| eval: FALSE
import polars as pl

pl.read_parquet("data/signatures-by-run").filter(
    pl.col("signature").is_in(["grouppred_cvpcr", "137subjmap_weighted_mean"])
).filter(pl.col("task") == "cuff", pl.col("run") == 1).rename(
    {"correlation": "value"}
).select(
    "signature",
    "value",
    "sub",
    "ses",
).pivot(
    on="signature", index=["sub", "ses"]
).rename(
    {"grouppred_cvpcr": "NPS", "137subjmap_weighted_mean": "SIIPS1"}
)

```

```bash
shape: (716, 4)
┌───────┬─────┬───────────┬───────────┐
│ sub   ┆ ses ┆ SIIPS1    ┆ NPS       │
│ ---   ┆ --- ┆ ---       ┆ ---       │
│ i64   ┆ str ┆ f64       ┆ f64       │
╞═══════╪═════╪═══════════╪═══════════╡
│ 10003 ┆ V1  ┆ -0.001619 ┆ 0.033091  │
│ 10008 ┆ V1  ┆ -0.040698 ┆ -0.058134 │
│ 10010 ┆ V1  ┆ -0.061107 ┆ -0.019997 │
│ 10011 ┆ V1  ┆ -0.006518 ┆ -0.074017 │
│ 10013 ┆ V1  ┆ -0.027933 ┆ 0.023413  │
│ …     ┆ …   ┆ …         ┆ …         │
│ 25266 ┆ V1  ┆ -0.058184 ┆ -0.032597 │
│ 25271 ┆ V1  ┆ -0.039983 ┆ -0.092517 │
│ 25273 ┆ V1  ┆ -0.038248 ┆ -0.02306  │
│ 25275 ┆ V1  ┆ -0.052387 ┆ -0.06732  │
│ 25277 ┆ V1  ┆ 0.023143  ┆ -0.063882 │
└───────┴─────┴───────────┴───────────┘
```

## Considerations While Working on the Project

### Variability Across Scanners

{{< include _snippets/mri-scanner-variability.qmd >}}

### Data Quality

{{< include _snippets/mri-qc.qmd >}}

### Signature Response Measure

The signature responses were extracted using best-practices, but the imaging DIRC is currently exploring alternative ways of calculating signature responses in the CUFF tasks. For details and progress, please see [Imaging Analysis Ideas | NPS+SIIPS1 on ToPS or SpaceTop Data](https://a2cps.atlassian.net/wiki/spaces/DOC/pages/5406923/Imaging+Analysis+Ideas#NPS%2BSIIPS1-on-ToPS-or-SpaceTop-Data).

### Intermediate Outputs

The other folders contain intermediate outputs that may be useful for digging into a participant's results

- confounds
  - The nuisance timeseries that were used during denoising
- cleaned
  - The NifTI files of functional MRI after denoising (e.g., temporal filter, nuisance regression)
