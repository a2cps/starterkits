{
  "hash": "a2c1b2205644b3e80d556c4996eb3b5b",
  "result": {
    "engine": "knitr",
    "markdown": "---\nformat:\n  html:\n    df-print: tibble\n---\n\n# Prior Neural Pain Signature Responses {#sec-neural-pain-signatures}\n\n## Before Proposing Project\n\n### Confirm Sample Size\n\nNot all participants in a release have imaging, and depending on the application not all MRIs may be of sufficient quality. Before proposing a project, please confirm that a release will have a large enough sample size. Release 2.0 has 716 participants with the primary task fMRI biomarker: NPS [@wager_fmri-based_2013] and SIIPS-1 [@woo_quantifying_2017]. \n\n## Starting Project\n\n### Locate data\n\nOn TACC, the neuroimaging data are stored underneath the releases. For example, data release v2.#.# is underneath\n\n```bash\npre-surgery/mris\n```\n\n\nThe signature response are underneath `derivatives/signatures`\n\n```bash\n$ ls derivatives/signatures/\ncleaned    confounds.json      signatures-by-part-diff       signatures-by-part.json  signatures-by-run-diff       signatures-by-run.json  signatures-by-tr-diff       signatures-by-tr.json\nconfounds  signatures-by-part  signatures-by-part-diff.json  signatures-by-run        signatures-by-run-diff.json  signatures-by-tr        signatures-by-tr-diff.json\n```\n\nSignature responses are stored either \"by-run\" (that is, one response per scan), \"by-part\" (three responses per run corresponding to the three parts for which participants provided pain ratings), or \"by-tr\" (one response for every volume). The biomarker corresponds to the values that are \"by-run\". Additionally, responses may be calculated with only the data from a single run (e.g., a \"by-run\" response for REST1, CUFF1, CUFF2, and REST2), or they may be calculated as a difference (\"diff\") between one of the CUFF scans and one of the REST scans. \n\nEach signature response folder contains a table of values, and `*.json` sidecars are [data dictionaries that conform to BIDS ](https://bids-specification.readthedocs.io/en/v1.9.0/common-principles.html#tabular-files). The data dictionary for responses \"by-run\" is copied below.\n\n```json\n{\n    \"signature\": {\n        \"LongName\": \"Signature\",\n        \"Description\": \"Index for of Signature. See signature_labels.json\"\n    },\n    \"correlation\": {\n        \"LongName\": \"Correlation\",\n        \"Description\": \"Signature as Estimated by Correlation\"\n    },\n    \"dot\": {\n        \"LongName\": \"Dot Product\",\n        \"Description\": \"Signature as Estimated by Dot Product\"\n    },\n    \"cosine\": {\n        \"LongName\": \"Cosine Similarity\",\n        \"Description\": \"Signature as Estimated by Cosine Similarity\"\n    },\n    \"sub\": {\n        \"LongName\": \"Subject\",\n        \"Description\": \"Study Participant, BIDS Subject ID\",\n        \"TermURL\": \"https://bids-specification.readthedocs.io/en/v1.9.0/appendices/entities.html#sub\"\n    },\n    \"ses\": {\n        \"LongName\": \"Session\",\n        \"Description\": \"Visit, Protocol, BIDS Session ID\",\n        \"Levels\": {\n            \"V1\": \"baseline_visit\",\n            \"V3\": \"3mo_postop\"\n        },\n        \"TermURL\": \"https://bids-specification.readthedocs.io/en/v1.9.0/appendices/entities.html#ses\"\n    },\n    \"task\": {\n        \"LongName\": \"Task\",\n        \"Description\": \"Functional MRI Task, BIDS Task ID\",\n        \"Levels\": {\n            \"cuff\": \"cuff pressure scan\",\n            \"rest\": \"resting state scan\"\n        },\n        \"TermURL\": \"https://bids-specification.readthedocs.io/en/v1.9.0/appendices/entities.html#task\"\n    },\n    \"run\": {\n        \"LongName\": \"Run\",\n        \"Description\": \"Task Run Number, BIDS Run ID\",\n        \"TermURL\": \"https://bids-specification.readthedocs.io/en/v1.9.0/appendices/entities.html#run\"\n    }\n}\n```\n\nNote: the table mentions \"session\", but in this release only V1 (baseline) results are available.\n\n### Extract data\n\nThe tabular data comprise parquet files that have been partitioned in a [hive-style](https://hive.apache.org/). That is, subfolder names contain column information – in this case subject ID (REDCap Record ID), task, and run. \n\n```bash\n$ tree signature-by-run\nsignature-by-run\n├── sub=10003\n│  └── ses=V1\n│     ├── task=cuff\n│     │  └── run=1\n│     │     └── part-0.parquet\n│     └── task=rest\n│        ├── run=1\n│        │  └── part-0.parquet\n│        └── run=2\n│           └── part-0.parquet\n├── sub=10008\n│  └── ses=V1\n│     ├── task=cuff\n│     │  └── run=1\n│     │     └── part-0.parquet\n│     └── task=rest\n│        ├── run=1\n│        │  └── part-0.parquet\n│        └── run=2\n```\n\nThe biomarker is based on the CUFF1 (task=cuff/run=1) scan. The other scans are available for secondary analyses, but please note that not all participants have all tasks and runs available.\n\nTo load the whole dataset, the parquet files may be read individually or using a tool that is aware of the hive-partitioning structure. In `R`, a good choice is the [`arrow`](https://arrow.apache.org/docs/r/index.html) library.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(arrow)\nlibrary(dplyr)\nlibrary(tidyr)\n\nopen_dataset(\"data/signatures-by-run\") |>\n  filter(signature %in% c(\"grouppred_cvpcr\", \"137subjmap_weighted_mean\")) |>\n  filter(task == \"cuff\", run == 1) |>\n  select(signature, value = correlation, sub, ses) |>\n  collect() |>\n  pivot_wider(names_from = signature) |>\n  rename(\n    SIIPS1 = `137subjmap_weighted_mean`,\n    NPS = `grouppred_cvpcr`\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 716 × 4\n     sub ses     SIIPS1      NPS\n   <int> <chr>    <dbl>    <dbl>\n 1 10003 V1    -0.00162  0.0331 \n 2 10010 V1    -0.0611  -0.0200 \n 3 10011 V1    -0.00652 -0.0740 \n 4 10008 V1    -0.0407  -0.0581 \n 5 10013 V1    -0.0279   0.0234 \n 6 10014 V1    -0.00120 -0.0146 \n 7 10017 V1    -0.0165   0.0263 \n 8 10015 V1    -0.0576  -0.0178 \n 9 10020 V1    -0.0103  -0.0530 \n10 10023 V1     0.0116  -0.00789\n# ℹ 706 more rows\n```\n\n\n:::\n:::\n\n\n\nIn python, a good choice is the [`polars`](https://docs.pola.rs/) library\n\n::: {.cell}\n\n```{.python .cell-code}\nimport polars as pl\n\npl.read_parquet(\"data/signatures-by-run\").filter(\n    pl.col(\"signature\").is_in([\"grouppred_cvpcr\", \"137subjmap_weighted_mean\"])\n).filter(pl.col(\"task\") == \"cuff\", pl.col(\"run\") == 1).rename(\n    {\"correlation\": \"value\"}\n).select(\n    \"signature\",\n    \"value\",\n    \"sub\",\n    \"ses\",\n).pivot(\n    on=\"signature\", index=[\"sub\", \"ses\"]\n).rename(\n    {\"grouppred_cvpcr\": \"NPS\", \"137subjmap_weighted_mean\": \"SIIPS1\"}\n)\n```\n:::\n\n```bash\nshape: (716, 4)\n┌───────┬─────┬───────────┬───────────┐\n│ sub   ┆ ses ┆ SIIPS1    ┆ NPS       │\n│ ---   ┆ --- ┆ ---       ┆ ---       │\n│ i64   ┆ str ┆ f64       ┆ f64       │\n╞═══════╪═════╪═══════════╪═══════════╡\n│ 10003 ┆ V1  ┆ -0.001619 ┆ 0.033091  │\n│ 10008 ┆ V1  ┆ -0.040698 ┆ -0.058134 │\n│ 10010 ┆ V1  ┆ -0.061107 ┆ -0.019997 │\n│ 10011 ┆ V1  ┆ -0.006518 ┆ -0.074017 │\n│ 10013 ┆ V1  ┆ -0.027933 ┆ 0.023413  │\n│ …     ┆ …   ┆ …         ┆ …         │\n│ 25266 ┆ V1  ┆ -0.058184 ┆ -0.032597 │\n│ 25271 ┆ V1  ┆ -0.039983 ┆ -0.092517 │\n│ 25273 ┆ V1  ┆ -0.038248 ┆ -0.02306  │\n│ 25275 ┆ V1  ┆ -0.052387 ┆ -0.06732  │\n│ 25277 ┆ V1  ┆ 0.023143  ┆ -0.063882 │\n└───────┴─────┴───────────┴───────────┘\n```\n\n## Considerations While Working on the Project\n\n### Variability Across Scanners\n\nMany MRI biomarkers exhibit variability across the scanners, which may confound some analyses. For an up-to-date assessment of the issue and overview of current thinking, please see [Confluence](https://a2cps.atlassian.net/wiki/spaces/DOC/pages/176619539/Imaging+Harmonization). \n\n\n### Data Quality\n\nAs with any MRI derivative, all pipeline derivatives have been included. This means that products were included regardless of their quality, and so some products may have been generated from images that are known to have poor quality---rated \"red\", or incomparable. For details on the ratings and how to exclude them, see @sec-rawdata-mri-qc-joining. Additionally, extensive QC has not yet been performed on the derivatives themselves, and so there may be cases where pipelines produced atypical outputs. For an overview of planned checks, see [Confluence](https://a2cps.atlassian.net/wiki/spaces/DOC/pages/262471688/Image+Processing+Checks). \n\n\n### Signature Response Measure\n\nThe signature responses were extracted using best-practices, but the imaging DIRC is currently exploring alternative ways of calculating signature responses in the CUFF tasks. For details and progress, please see [Imaging Analysis Ideas | NPS+SIIPS1 on ToPS or SpaceTop Data](https://a2cps.atlassian.net/wiki/spaces/DOC/pages/5406923/Imaging+Analysis+Ideas#NPS%2BSIIPS1-on-ToPS-or-SpaceTop-Data).\n\n### Intermediate Outputs\n\nThe other folders contain intermediate outputs that may be useful for digging into a participant's results\n\n- confounds\n  - The nuisance timeseries that were used during denoising\n- cleaned\n  - The NifTI files of functional MRI after denoising (e.g., temporal filter, nuisance regression)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}